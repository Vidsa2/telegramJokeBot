{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88f58ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os # operating system\n",
    "from dotenv import load_dotenv # load environment variables from .env file\n",
    "load_dotenv() # load the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "686d5ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88440db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d231a7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(\n",
    "    model=\"Gemma2-9b-It\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc424db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello, world! ðŸ‘‹\\n\\nHow can I help you today? ðŸ˜Š\\n', response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 11, 'total_tokens': 28, 'completion_time': 0.030909091, 'prompt_time': 0.003559792, 'queue_time': 0.343169622, 'total_time': 0.034468883}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-25a5103d-e44a-452f-b75f-12dfe8c4a3df-0', usage_metadata={'input_tokens': 11, 'output_tokens': 17, 'total_tokens': 28})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8f3daf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is **Paris**. ðŸ‡«ðŸ‡·  ', response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 16, 'total_tokens': 31, 'completion_time': 0.027272727, 'prompt_time': 0.001914605, 'queue_time': 0.179729369, 'total_time': 0.029187332}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-de0adf86-4fa8-46d3-88a0-eae64f01e3f0-0', usage_metadata={'input_tokens': 16, 'output_tokens': 15, 'total_tokens': 31})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\n",
    "    \"What is the capital of France?\",\n",
    "    stop=[\"\\n\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703e136e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a Standup Comedian AI. Generate a Big one joke based on the following topic:\"),\n",
    "        (\"user\", \" topic : {topic}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c1955ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a Standup Comedian AI. Generate a Big one joke based on the following topic:'), HumanMessage(content=' Topic : content=\"That\\'s a broad topic!  To give you a helpful response, I need you to be more specific. What about engineering interests you? \\\\n\\\\nFor example, are you curious about:\\\\n\\\\n* **Different types of engineering?** (e.g., civil, mechanical, electrical, chemical, aerospace)\\\\n* **How engineers work?** (e.g., the design process, using software, teamwork)\\\\n* **Specific engineering projects or innovations?** (e.g., the International Space Station, self-driving cars, renewable energy)\\\\n* **How to become an engineer?** (e.g., education requirements, career paths)\\\\n\\\\nOnce you tell me what you\\'d like to know, I can provide you with relevant information and resources.\\\\n\" response_metadata={\\'token_usage\\': {\\'completion_tokens\\': 160, \\'prompt_tokens\\': 11, \\'total_tokens\\': 171, \\'completion_time\\': 0.290909091, \\'prompt_time\\': 0.002623467, \\'queue_time\\': 0.209380001, \\'total_time\\': 0.293532558}, \\'model_name\\': \\'Gemma2-9b-It\\', \\'system_fingerprint\\': \\'fp_10c08bf97d\\', \\'finish_reason\\': \\'stop\\', \\'logprobs\\': None} id=\\'run-fa220108-3e2e-47a7-8c66-2da1dda8fc8e-0\\' usage_metadata={\\'input_tokens\\': 11, \\'output_tokens\\': 160, \\'total_tokens\\': 171}')])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke(model.invoke(\"Engineering\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d37b358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9658e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecf6245a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You ever notice how school is basically a giant scam?  They tell you it's about education, right? But really, it's all about prepping you for the real world, which is basically just a bigger, more expensive version of middle school cafeteria food.  Just sayin'! \\n\\n\\n\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"School\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44a5088f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the engineer bring a ladder to the bar? \\n\\nBecause they heard the drinks were on the house! ...Get it? Because engineers are always *leveling up*!  \\n\\n\\nLet me know if you want to hear another one!  ðŸ˜„  \\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic = input(\"Enter a topic for the joke: \")\n",
    "chain.invoke({\"topic\":topic})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56107586",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
